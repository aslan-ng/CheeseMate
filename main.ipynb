{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcVasdH1A3xvkMwCX7jpwl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aslan-ng/CheeseMate/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "\n",
        "!pip -q install --upgrade \"smolagents[transformers]\" gradio pandas"
      ],
      "metadata": {
        "id": "AGAqCpYY68VU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ctdtcHbjy9A1"
      },
      "outputs": [],
      "source": [
        "# Make imports\n",
        "\n",
        "import re\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from smolagents import TransformersModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Propmts and examples\n",
        "\n",
        "SYSTEM = \"\"\"\n",
        "You are CheeseMatch, a friendly assistant that ONLY recommends cheeses.\n",
        "- Stay strictly in the cheese domain; if asked anything else, politely redirect.\n",
        "- Be concise and conversational (1–3 sentences).\n",
        "- Give 1–3 cheese suggestions max, with a brief why (taste/texture/use/diet notes).\n",
        "- Prefer widely available cheeses unless the user requests niche options.\n",
        "- If constraints are unclear, ask ONE short clarification question.\n",
        "- Never output JSON, tables, or code.\n",
        "\"\"\"\n",
        "\n",
        "FEWSHOT = \"\"\"\n",
        "User: Where is the capital of France?\n",
        "Assistant: I can only help you select good cheese! Do you want me to suggest a cheese?\n",
        "\n",
        "User: I'm lactose intolerant and I don't like salty cheese. What do you recommend?\n",
        "Assistant: Consider naturally low-lactose, milder cheeses like Swiss-style options; they tend to be easier on lactose and not overly salty.\n",
        "\n",
        "User: Low fat, high protein cheeses\n",
        "Assistant: Cottage cheese is a solid choice—high in protein and available in low-fat varieties.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eFePeb25-K5R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model (Qwen)\n",
        "\n",
        "def create_model(parameters: float = 0.5):\n",
        "    MODEL_ID = f\"Qwen/Qwen2.5-{PARAMETERS_COUNT}B-Instruct\"\n",
        "    model = TransformersModel(\n",
        "        model_id=MODEL_ID,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=\"auto\",\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "EGGZjYas3MZa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main body of program that combines them all\n",
        "\n",
        "def _to_text(reply) -> str:\n",
        "    \"\"\"\n",
        "    Function to convert smolagents ChatMessage (or str) to plain text.\n",
        "    \"\"\"\n",
        "    if isinstance(reply, str):\n",
        "        return reply\n",
        "    # Try common ChatMessage shapes\n",
        "    try:\n",
        "        content = reply.content  # may be str or list of parts\n",
        "        if isinstance(content, str):\n",
        "            return content\n",
        "        if isinstance(content, list):\n",
        "            # look for a text-like part\n",
        "            for part in content:\n",
        "                if isinstance(part, dict):\n",
        "                    if part.get(\"type\") in {\"text\", \"output_text\"} and \"text\" in part:\n",
        "                        return part[\"text\"]\n",
        "                elif hasattr(part, \"text\"):\n",
        "                    return part.text\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Fallback\n",
        "    return str(reply)\n",
        "\n",
        "\n",
        "class CheeseChat:\n",
        "    \"\"\"\n",
        "    CheeseMatch assistant.\n",
        "    \"\"\"\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.awaiting_confirm = False\n",
        "\n",
        "    def respond(self, user_text: str) -> str:\n",
        "        t = user_text.strip()\n",
        "        tl = t.lower()\n",
        "\n",
        "        # If we previously redirected and the user confirms\n",
        "        if self.awaiting_confirm and tl in {\"yes\", \"yes!\", \"ok\", \"okay\", \"sure\", \"yep\"}:\n",
        "            self.awaiting_confirm = False\n",
        "            prompt = FEWSHOT + \"\\n\\nUser: Please suggest a good cheese.\\nAssistant:\"\n",
        "            reply = self.model.generate(\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": SYSTEM}]},\n",
        "                    {\"role\": \"user\",   \"content\": [{\"type\": \"text\", \"text\": prompt}]},\n",
        "                ],\n",
        "            )\n",
        "            return _to_text(reply).strip()\n",
        "\n",
        "        # Default: cheese-only assistant behavior (FEWSHOT carries the redirect example)\n",
        "        prompt = FEWSHOT + f\"\\n\\nUser: {t}\\nAssistant:\"\n",
        "        reply = self.model.generate(\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": SYSTEM}]},\n",
        "                {\"role\": \"user\",   \"content\": [{\"type\": \"text\", \"text\": prompt}]},\n",
        "            ],\n",
        "        )\n",
        "        text = _to_text(reply).strip()\n",
        "\n",
        "        # If the model chose to redirect (e.g., off-topic question),\n",
        "        # remember to expect a confirmation on the next turn.\n",
        "        if \"do you want me to suggest a cheese\" in text.lower():\n",
        "            self.awaiting_confirm = True\n",
        "\n",
        "        return text\n",
        "\n",
        "\n",
        "#df = pd.read_csv(\"data.csv\")"
      ],
      "metadata": {
        "id": "--RnDBbN3WVx",
        "outputId": "76ca3f42-be38-4339-928c-c16c1d436678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1742117841.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the bot\n",
        "\n",
        "PARAMETERS_COUNT = 0.5  # Billions\n",
        "model = create_model(PARAMETERS_COUNT)\n",
        "bot = CheeseChat(model)"
      ],
      "metadata": {
        "id": "CiFxbAaq-QOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some examples without GUI\n",
        "\n",
        "#message = \"I'm lactose intolerant and I don't like salty cheese. what do you recommend?\"\n",
        "#print(message)\n",
        "#print(bot.respond(message))\n",
        "\n",
        "#message = \"Where is the capital of France?\"\n",
        "#print(message)\n",
        "#print(bot.respond(message))"
      ],
      "metadata": {
        "id": "3yr52fUw-vLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create GUI\n",
        "\n",
        "with gr.Blocks(theme=\"soft\") as demo:\n",
        "    gr.Markdown(\"## 🧀 CheeseMatch\\nI only help you select good cheese. Ask away!\")\n",
        "\n",
        "    chat = gr.Chatbot(height=420, type=\"messages\")  # type='messages' keeps roles tidy\n",
        "    txt = gr.Textbox(placeholder=\"Type your message about cheese…\", autofocus=True)\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    def user_submit(user_message, history):\n",
        "        # history is a list of dicts: [{\"role\":\"user\"/\"assistant\",\"content\":...}, ...]\n",
        "        history = history or []\n",
        "        history.append({\"role\": \"user\", \"content\": user_message})\n",
        "        bot_reply = bot.respond(user_message)\n",
        "        history.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "        return gr.update(value=history), gr.update(value=\"\")\n",
        "\n",
        "    def clear_fn():\n",
        "        # Reset bot state between conversations if you want\n",
        "        global bot\n",
        "        bot = CheeseChat()\n",
        "        return [], \"\"\n",
        "\n",
        "    txt.submit(user_submit, [txt, chat], [chat, txt])\n",
        "    clear.click(clear_fn, [], [chat, txt])\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "WKLEmjLXBTrH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}